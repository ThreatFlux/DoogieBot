services:
  app:
    # Remove image: line and add build: section
    build:
      context: .
      dockerfile: Dockerfile
      args:
        # Pass the host's Docker GID. Found using: getent group docker | cut -d: -f3
        DOCKER_GID: 984
        # You can also pass USER_ID and GROUP_ID if needed, otherwise defaults from Dockerfile are used
        # USER_ID: 1000
        # GROUP_ID: 1000
    ports:
      - "3000:3000"  # Frontend
      - "8000:8000"  # Backend API
    volumes:
      # Use more specific bind mounts for development
      - ./backend:/app/backend  # Bind mount for backend development
      - ./frontend:/app/frontend  # Bind mount for frontend development
      # --- MODIFIED: Use Docker Desktop socket path ---
      - /home/vtriple/.docker/desktop/docker.sock k:/var/run/docker.sock  # Mount Docker socket THIS HASTO BE THE PATH FOR YOUR DOCKER DESKTOP
      # --- END MODIFIED ---
      - ./data/db:/app/data/db  # Persist database files
      - ./data/indexes:/app/data/indexes  # Persist index files
      - ./entrypoint.sh:/app/entrypoint.sh  # Mount the entrypoint script
      - /app/.venv # Use anonymous volume for venv outside backend mount
      - /app/frontend/node_modules # Use anonymous volume for node_modules
      # Removed anonymous volume for pnpm store; let it use node_modules
      # Exclude build artifacts from host machine
      #- /app/frontend/.next
      #- /app/backend/__pycache__
    environment:
      - NODE_ENV=development
      - PYTHONPATH=/app
      - FASTAPI_ENV=development
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-change-in-production}
      - ALGORITHM=HS256
      - DISABLE_SQL_LOGS=true
      - ACCESS_TOKEN_EXPIRE_MINUTES=30
      - FIRST_ADMIN_EMAIL=${FIRST_ADMIN_EMAIL:-admin@example.com}
      - FIRST_ADMIN_PASSWORD=${FIRST_ADMIN_PASSWORD:-change-this-password}
      # LLM Service environment variables
      - OPENAI_API_KEY=${OPENAI_API_KEY:-dummy_key_for_testing}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://192.168.40.106:11434}
      - LM_STUDIO_BASE_URL=${LM_STUDIO_BASE_URL:-http://localhost:8000}
      # Memory management
      - PYTHONMALLOC=debug
      - PYTHONWARNINGS=always
      # MCP configuration
      - MCP_NETWORK=mcp-network
      - MCP_DATA_DIR=/var/lib/doogie-chat/mcp
      - MCP_ENABLE_DOCKER=true
      - LLM_DEBUG_LOGGING=true # Enable detailed LLM request/response logging
    restart: unless-stopped
    entrypoint: ["/app/entrypoint.sh"]
    # Add memory limits to prevent OOM issues
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'
    # Add healthcheck
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
